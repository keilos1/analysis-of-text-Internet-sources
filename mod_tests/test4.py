import pytest
from unittest.mock import AsyncMock, MagicMock, patch
from datetime import datetime
from application.data_collection.socialScraper import SocialScraper
import re


class TestSocialScraper:
    @pytest.fixture
    def scraper(self):
        return SocialScraper()

    @pytest.fixture
    def telegram_html(self):
        return """
        <div class="tgme_widget_message">
            <div class="tgme_widget_message_text">–¢–µ—Å—Ç–æ–≤—ã–π –ø–æ—Å—Ç –≤ Telegram üöÄ</div>
            <time datetime="2023-01-01T12:00:00+00:00"></time>
            <a class="tgme_widget_message_date" href="https://t.me/channel/123"></a>
        </div>
        """

    # –¢–µ—Å—Ç –ú15: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Telegram
    @pytest.mark.asyncio
    @patch('httpx.AsyncClient.get')
    async def test_collect_social_data_success(self, mock_get, scraper, telegram_html):
        """–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π —Ç–µ—Å—Ç —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Telegram"""
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–∫–æ–≤
        mock_response = MagicMock()
        mock_response.status_code = 200
        mock_response.text = telegram_html
        mock_get.return_value = mock_response

        sources = [{
            "source_id": "tg_test",
            "url": "https://t.me/test_channel",
            "name": "Test Channel"
        }]

        result = await scraper.collect_social_data(sources)

        assert "tg_test" in result
        assert len(result["tg_test"]) == 1
        assert result["tg_test"][0]["title"] == "–¢–µ—Å—Ç–æ–≤—ã–π –ø–æ—Å—Ç –≤ Telegram"

    # –¢–µ—Å—Ç –ú16: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–∞–Ω–∞–ª–∞
    @pytest.mark.asyncio
    @patch('httpx.AsyncClient.get')
    async def test_collect_social_data_invalid_channel(self, mock_get, scraper):
        """–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–∞–Ω–∞–ª–∞"""
        mock_response = MagicMock()
        mock_response.status_code = 404
        mock_get.return_value = mock_response

        sources = [{
            "source_id": "tg_invalid",
            "url": "https://t.me/nonexistent",
            "name": "Nonexistent"
        }]

        result = await scraper.collect_social_data(sources)
        assert result == {}

    # –¢–µ—Å—Ç –ú17: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ—Å—Ç–∞ Telegram
    @pytest.mark.asyncio
    async def test_parse_telegram_success(self, scraper, telegram_html):
        """–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π —Ç–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML Telegram"""
        mock_client = AsyncMock()
        mock_source = {
            "source_id": "tg_test",
            "url": "https://t.me/test_channel"
        }

        with patch('bs4.BeautifulSoup', return_value=BeautifulSoup(telegram_html, 'html.parser')):
            posts = await scraper._parse_telegram(mock_client, mock_source)

            assert len(posts) == 1
            post = posts[0]
            assert post["title"] == "–¢–µ—Å—Ç–æ–≤—ã–π –ø–æ—Å—Ç –≤ Telegram"
            assert "üöÄ" not in post["text"]  # –≠–º–æ–¥–∑–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É–¥–∞–ª–µ–Ω—ã
            assert post["published_at"] == datetime(2025, 5, 1, 12, 0)

    # –¢–µ—Å—Ç –ú18: –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∏—Ç–æ–≥–æ HTML
    @pytest.mark.asyncio
    async def test_parse_telegram_invalid_html(self, scraper):
        """–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –±–∏—Ç–æ–≥–æ HTML"""
        mock_client = AsyncMock()
        mock_source = {
            "source_id": "tg_test",
            "url": "https://t.me/test_channel"
        }

        posts = await scraper._parse_telegram(mock_client, mock_source)
        assert posts == []

    # –¢–µ—Å—Ç –ú19: –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —ç–º–æ–¥–∑–∏
    def test_remove_emojis(self, scraper):
        """–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π —Ç–µ—Å—Ç —É–¥–∞–ª–µ–Ω–∏—è —ç–º–æ–¥–∑–∏"""
        text = "–ü—Ä–∏–≤–µ—Ç üöÄ –∫–∞–∫ –¥–µ–ª–∞? üòä"
        result = scraper._remove_emojis(text)
        assert "üöÄ" not in result
        assert "üòä" not in result
        assert "–ü—Ä–∏–≤–µ—Ç –∫–∞–∫ –¥–µ–ª–∞?" in result

    # –¢–µ—Å—Ç –ú20: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ —ç–º–æ–¥–∑–∏
    def test_remove_emojis_no_emojis(self, scraper):
        """–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ —ç–º–æ–¥–∑–∏"""
        text = "–û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ —ç–º–æ–¥–∑–∏"
        result = scraper._remove_emojis(text)
        assert result == text

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–µ—Ä–µ—Å–ª–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    def test_is_forwarded_message(self, scraper):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–µ—Ä–µ—Å–ª–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
        html = """
        <div class="tgme_widget_message">
            <div class="tgme_widget_message_forwarded_from"></div>
            <div class="tgme_widget_message_text"></div>
        </div>
        """
        soup = BeautifulSoup(html, 'html.parser')
        assert scraper._is_forwarded_message(soup) is True

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—á–∏—Å—Ç–∫–∏ —Ñ—É—Ç–µ—Ä–∞
    def test_clean_footer_text(self, scraper):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ—É—Ç–µ—Ä–∞"""
        text = "–¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è\n–§–∞–∫—Ç–æ—Ä –ù–æ–≤–æ—Å—Ç–∏ | –ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è"
        result = scraper._clean_footer_text(text)
        assert "–§–∞–∫—Ç–æ—Ä –ù–æ–≤–æ—Å—Ç–∏" not in result
        assert "–¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è" in result